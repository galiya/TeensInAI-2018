{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Task 1: Analyse an image (Computer Vision API)\n\nThe image below is taken from [one of the posts](http://acornaspirations.com/teensinai-learning-about-ai-by-doing-ai-by-christy-forshaw-14/) in the TeensInAI blog. We will use Microsoft Computer Vision API to analyse it. We will initially pull out all the information provided by the API endpoint, and later narrow it down to colours availabl on the image, as well as pull out a caption, generated by the service for this image. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![alt text](http://acornaspirations.com/wp-content/uploads/2018/04/30704125_969873169844594_1366134607577088_n-300x225.jpg)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To be able to use this service you need to have access to [Azure Portal](http://portal.azure.com) and create an instance of the Vision API Cognitive Service."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "First, let's try calling the service to analyse the given image and return all available feautures, as decribed in the [API Reference](https://westus.dev.cognitive.microsoft.com/docs/services/56f91f2d778daf23d8ec6739/operations/56f91f2e778daf14a499e1fa)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "visionapi_key = #'INSERT YOUR API KEY HERE'",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'language': 'en',\n    'visualFeatures': 'Categories, Description, Tags, Faces, ImageType, Color'\n    #'visualFeatures': 'Description' #Demo 2\n    \n})\n\nbody = \"{'url':'http://acornaspirations.com/wp-content/uploads/2018/04/30704125_969873169844594_1366134607577088_n-300x225.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/analyze?%s\" % params, body, headers)\n    response = conn.getresponse()\n    data = response.read()\n\n    # 'data' contains the JSON data. The following formats the JSON data for display.\n    parsed = json.loads(data.decode())\n    print (\"Response:\")\n    print (json.dumps(parsed, sort_keys=True, indent=2))\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n{\n  \"description\": {\n    \"captions\": [\n      {\n        \"confidence\": 0.8986100455325486, \n        \"text\": \"a group of people standing in front of a crowd posing for the camera\"\n      }\n    ], \n    \"tags\": [\n      \"person\", \n      \"people\", \n      \"group\", \n      \"man\", \n      \"holding\", \n      \"standing\", \n      \"posing\", \n      \"sitting\", \n      \"young\", \n      \"child\", \n      \"front\", \n      \"woman\", \n      \"table\", \n      \"large\", \n      \"crowd\", \n      \"red\", \n      \"boy\", \n      \"cake\", \n      \"glasses\", \n      \"room\", \n      \"suit\", \n      \"kite\", \n      \"court\", \n      \"playing\"\n    ]\n  }, \n  \"metadata\": {\n    \"format\": \"Jpeg\", \n    \"height\": 225, \n    \"width\": 300\n  }, \n  \"requestId\": \"bdb7c0f9-c682-4513-914e-0ea035e4aecd\"\n}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can also choose to only pick up the caption from the response and process it as required (show it below, in our case)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'language': 'en',\n    'visualFeatures': 'Description'\n    #'visualFeatures': 'Description' #Demo 2\n    \n})\n\nbody = \"{'url':'http://acornaspirations.com/wp-content/uploads/2018/04/30704125_969873169844594_1366134607577088_n-300x225.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/analyze?%s\" % params, body, headers)\n    response = conn.getresponse()\n    data = response.read()\n\n    parsed = json.loads(data.decode())\n    caption = json.dumps(parsed['description']['captions'][0], sort_keys=True, indent=2)\n    print (\"Response:\")\n    print (caption)\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n{\n  \"confidence\": 0.8986100455325486, \n  \"text\": \"a group of people standing in front of a crowd posing for the camera\"\n}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There is also a separate API call that can be used to get various descriptions for a given image: [Describe Image](https://westus.dev.cognitive.microsoft.com/docs/services/56f91f2d778daf23d8ec6739/operations/56f91f2e778daf14a499e1fe) API endpoint. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'maxCandidates': 5    #Maximum number of candidate descriptions to be returned. The default is 1.\n})\n\nbody = \"{'url':'http://acornaspirations.com/wp-content/uploads/2018/04/30704125_969873169844594_1366134607577088_n-300x225.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/describe?%s\" % params, body, headers) # \"describe\" method\n    response = conn.getresponse()\n    data = response.read()\n\n    parsed = json.loads(data.decode())\n    caption = json.dumps(parsed[\"description\"][\"captions\"], sort_keys=True, indent=2)\n    print (\"Response:\")\n    print (caption)\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n[\n  {\n    \"confidence\": 0.8986100455325486, \n    \"text\": \"a group of people standing in front of a crowd posing for the camera\"\n  }, \n  {\n    \"confidence\": 0.8976100455325486, \n    \"text\": \"a group of people in front of a crowd posing for the camera\"\n  }, \n  {\n    \"confidence\": 0.8966100455325486, \n    \"text\": \"a group of people posing for the camera\"\n  }, \n  {\n    \"confidence\": 0.8956100455325486, \n    \"text\": \"a group of people standing in front of a crowd\"\n  }, \n  {\n    \"confidence\": 0.8619496004170965, \n    \"text\": \"a group of people sitting in front of a crowd posing for the camera\"\n  }\n]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "   ## Task 2: Translate the image caption using Translator Text API\nLet's take another image from the blog and use it to demostrate translation capabilities combined with image analysis via [Translator Text API](https://azure.microsoft.com/en-gb/services/cognitive-services/translator-text-api/) \n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![alt text](http://acornaspirations.com/wp-content/uploads/bfi_thumb/kids1_32107776204_o-n4d4ca9kqkt3e7pdjqg27q6kpf7shwip991bfv9bfs.jpg)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Firstly, let's generate a description for this image (as we've done above)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nbody = \"{'url':'http://acornaspirations.com/wp-content/uploads/bfi_thumb/kids1_32107776204_o-n4d4ca9kqkt3e7pdjqg27q6kpf7shwip991bfv9bfs.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/describe\", body, headers) # \"describe\" method\n    response = conn.getresponse()\n    data = response.read()\n\n    parsed = json.loads(data.decode())\n    \n    caption_text = parsed['description']['captions'][0][\"text\"]\n    \n    print (\"Caption >> \" + caption_text)\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Caption >> a group of people sitting at a table using a laptop computer\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we have a caption, let's use a different API to translate that into a different language."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests, xml.etree.ElementTree as ET \n\n# Authenticate \ntranslateapi_key = #\"INSERT YOUR TRANSLATOR TEXT API KEY HERE\" \n\nauthentication_url = 'https://api.cognitive.microsoft.com/sts/v1.0/issueToken'\nauthentication_headers = {'Ocp-Apim-Subscription-Key': translateapi_key}\nauthentication_token = requests.post(authentication_url, headers=authentication_headers).text\n\n# Call the Text Translate API\n\ntranslate_url = 'https://api.microsofttranslator.com/v2/http.svc/Translate'\nparams = {\n    'appid': 'Bearer '+ authentication_token, \n    'text': caption_text, \n    'to': \"ru\"   # language to be used for translation\n} \n\ntranslate_headers = {'Accept': 'application/xml'}\ntranslate_response = requests.get(translate_url, params=params, headers=translate_headers) \ncaption_translation = ET.fromstring(translate_response.text.encode('utf-8')).text\n\nprint (\"Caption (translated) >> \" + caption_translation)\n",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Caption (translated) >> Группа людей, сидя за столом с помощью портативного компьютера\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The End!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}